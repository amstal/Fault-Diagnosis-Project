{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "listdirs = [\"Healthy\", \"Motor_1_Steady_state_error\", \"Motor_1_Stuck\", \"Motor_2_Steady_state_error\", \"Motor_2_Stuck\", \"Motor_3_Steady_state_error\", \"Motor_3_Stuck\", \"Motor_4_Steady_state_error\", \"Motor_4_Stuck\"]\n",
    "path = \"training_csv/\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_ratio:float, training:bool, path, directories_list, backend):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.backend = backend\n",
    "        self.training_ratio = training_ratio\n",
    "        self.directories_list = directories_list\n",
    "        self.data = []\n",
    "\n",
    "        for i, folder in enumerate(self.directories_list):\n",
    "            folderpath = os.path.join(path, folder)\n",
    "            files = os.listdir(folderpath)\n",
    "            number_files = len(files)\n",
    "            for n, file in enumerate(files):\n",
    "                if n < self.training_ratio * number_files and training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32).to(self.backend)\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "                elif n >= self.training_ratio * number_files and not training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32).to(self.backend)\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "training_set = dataset(training_ratio=0.9, training=True, path=path, directories_list=listdirs, backend=device)\n",
    "trainingloader = torch.utils.data.DataLoader(training_set, shuffle=True, batch_size=512)\n",
    "\n",
    "testing_set = dataset(training_ratio=0.9, training=False, path=path, directories_list=listdirs, backend=device)\n",
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{torch.Size([999, 6]): 3240} {torch.Size([999, 6]): 360}\n"
     ]
    }
   ],
   "source": [
    "shapes1 = {}\n",
    "for data in training_set.data:\n",
    "    if data[0].shape not in shapes1.keys():\n",
    "        shapes1[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes1[data[0].shape] += 1\n",
    "\n",
    "shapes2 = {}\n",
    "for data in testing_set.data:\n",
    "    if data[0].shape not in shapes2.keys():\n",
    "        shapes2[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes2[data[0].shape] += 1\n",
    "\n",
    "print(shapes1, shapes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, hidden_size, backend):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.backend = backend\n",
    "\n",
    "        self.LSTM = nn.LSTM(input_size=6, hidden_size=self.hidden_size, dropout=0.1, device=self.backend, batch_first=True, num_layers=2)\n",
    "        self.Linear = nn.Linear(in_features=self.hidden_size, out_features=9, device=self.backend)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM(x)[0]\n",
    "        x = self.Linear(x)\n",
    "        return x[:,-1]\n",
    "    \n",
    "Lstm = LSTM_model(100, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Lstm.parameters(), lr=1E-3)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, number of data 32, cost : 2.2099575996398926\n",
      "Epoch : 1, number of data 64, cost : 2.2010531425476074\n",
      "Epoch : 1, number of data 96, cost : 2.201347589492798\n",
      "Epoch : 1, number of data 128, cost : 2.205944776535034\n",
      "Epoch : 1, number of data 160, cost : 2.20237398147583\n",
      "Epoch : 1, number of data 192, cost : 2.195591926574707\n",
      "Epoch : 1, number of data 224, cost : 2.2064433097839355\n",
      "Epoch : 2, number of data 256, cost : 2.2008509635925293\n",
      "Epoch : 2, number of data 288, cost : 2.209639549255371\n",
      "Epoch : 2, number of data 320, cost : 2.2053675651550293\n",
      "Epoch : 2, number of data 352, cost : 2.2018208503723145\n",
      "Epoch : 2, number of data 384, cost : 2.197394847869873\n",
      "Epoch : 2, number of data 416, cost : 2.206498861312866\n",
      "Epoch : 2, number of data 448, cost : 2.199916124343872\n",
      "Epoch : 3, number of data 480, cost : 2.1959588527679443\n",
      "Epoch : 3, number of data 512, cost : 2.200099468231201\n",
      "Epoch : 3, number of data 544, cost : 2.2068328857421875\n",
      "Epoch : 3, number of data 576, cost : 2.207913637161255\n",
      "Epoch : 3, number of data 608, cost : 2.2030675411224365\n",
      "Epoch : 3, number of data 640, cost : 2.205615997314453\n",
      "Epoch : 3, number of data 672, cost : 2.2029762268066406\n",
      "Epoch : 4, number of data 704, cost : 2.2040019035339355\n",
      "Epoch : 4, number of data 736, cost : 2.1995022296905518\n",
      "Epoch : 4, number of data 768, cost : 2.2065508365631104\n",
      "Epoch : 4, number of data 800, cost : 2.2029387950897217\n",
      "Epoch : 4, number of data 832, cost : 2.2039172649383545\n",
      "Epoch : 4, number of data 864, cost : 2.1998181343078613\n",
      "Epoch : 4, number of data 896, cost : 2.2148213386535645\n",
      "Epoch : 5, number of data 928, cost : 2.212352752685547\n",
      "Epoch : 5, number of data 960, cost : 2.197732925415039\n",
      "Epoch : 5, number of data 992, cost : 2.20585298538208\n",
      "Epoch : 5, number of data 1024, cost : 2.2009265422821045\n",
      "Epoch : 5, number of data 1056, cost : 2.2049999237060547\n",
      "Epoch : 5, number of data 1088, cost : 2.1946702003479004\n",
      "Epoch : 5, number of data 1120, cost : 2.197998523712158\n",
      "Epoch : 6, number of data 1152, cost : 2.199075222015381\n",
      "Epoch : 6, number of data 1184, cost : 2.207287311553955\n",
      "Epoch : 6, number of data 1216, cost : 2.2023425102233887\n",
      "Epoch : 6, number of data 1248, cost : 2.2040905952453613\n",
      "Epoch : 6, number of data 1280, cost : 2.2051942348480225\n",
      "Epoch : 6, number of data 1312, cost : 2.199040412902832\n",
      "Epoch : 6, number of data 1344, cost : 2.2097229957580566\n",
      "Epoch : 7, number of data 1376, cost : 2.199199914932251\n",
      "Epoch : 7, number of data 1408, cost : 2.209327220916748\n",
      "Epoch : 7, number of data 1440, cost : 2.206817865371704\n",
      "Epoch : 7, number of data 1472, cost : 2.206068515777588\n",
      "Epoch : 7, number of data 1504, cost : 2.2025907039642334\n",
      "Epoch : 7, number of data 1536, cost : 2.1995229721069336\n",
      "Epoch : 7, number of data 1568, cost : 2.199103832244873\n",
      "Epoch : 8, number of data 1600, cost : 2.2002878189086914\n",
      "Epoch : 8, number of data 1632, cost : 2.200680732727051\n",
      "Epoch : 8, number of data 1664, cost : 2.19924259185791\n",
      "Epoch : 8, number of data 1696, cost : 2.20511531829834\n",
      "Epoch : 8, number of data 1728, cost : 2.207350730895996\n",
      "Epoch : 8, number of data 1760, cost : 2.204052686691284\n",
      "Epoch : 8, number of data 1792, cost : 2.2069263458251953\n",
      "Epoch : 9, number of data 1824, cost : 2.2023277282714844\n",
      "Epoch : 9, number of data 1856, cost : 2.206723213195801\n",
      "Epoch : 9, number of data 1888, cost : 2.1988680362701416\n",
      "Epoch : 9, number of data 1920, cost : 2.206676483154297\n",
      "Epoch : 9, number of data 1952, cost : 2.204000473022461\n",
      "Epoch : 9, number of data 1984, cost : 2.205496311187744\n",
      "Epoch : 9, number of data 2016, cost : 2.190258502960205\n",
      "Epoch : 10, number of data 2048, cost : 2.200519561767578\n",
      "Epoch : 10, number of data 2080, cost : 2.2045810222625732\n",
      "Epoch : 10, number of data 2112, cost : 2.203479290008545\n",
      "Epoch : 10, number of data 2144, cost : 2.1980948448181152\n",
      "Epoch : 10, number of data 2176, cost : 2.203162670135498\n",
      "Epoch : 10, number of data 2208, cost : 2.2058353424072266\n",
      "Epoch : 10, number of data 2240, cost : 2.2067553997039795\n",
      "Epoch : 11, number of data 2272, cost : 2.2036962509155273\n",
      "Epoch : 11, number of data 2304, cost : 2.209771156311035\n",
      "Epoch : 11, number of data 2336, cost : 2.206437110900879\n",
      "Epoch : 11, number of data 2368, cost : 2.2040908336639404\n",
      "Epoch : 11, number of data 2400, cost : 2.2023048400878906\n",
      "Epoch : 11, number of data 2432, cost : 2.19657039642334\n",
      "Epoch : 11, number of data 2464, cost : 2.1932194232940674\n",
      "Epoch : 12, number of data 2496, cost : 2.2017812728881836\n",
      "Epoch : 12, number of data 2528, cost : 2.2079622745513916\n",
      "Epoch : 12, number of data 2560, cost : 2.20967960357666\n",
      "Epoch : 12, number of data 2592, cost : 2.198126792907715\n",
      "Epoch : 12, number of data 2624, cost : 2.201643466949463\n",
      "Epoch : 12, number of data 2656, cost : 2.2042770385742188\n",
      "Epoch : 12, number of data 2688, cost : 2.196678876876831\n",
      "Epoch : 13, number of data 2720, cost : 2.1997032165527344\n",
      "Epoch : 13, number of data 2752, cost : 2.2094664573669434\n",
      "Epoch : 13, number of data 2784, cost : 2.207348346710205\n",
      "Epoch : 13, number of data 2816, cost : 2.1992533206939697\n",
      "Epoch : 13, number of data 2848, cost : 2.1970736980438232\n",
      "Epoch : 13, number of data 2880, cost : 2.2075209617614746\n",
      "Epoch : 13, number of data 2912, cost : 2.2094218730926514\n",
      "Epoch : 14, number of data 2944, cost : 2.207848072052002\n",
      "Epoch : 14, number of data 2976, cost : 2.200824022293091\n",
      "Epoch : 14, number of data 3008, cost : 2.1980786323547363\n",
      "Epoch : 14, number of data 3040, cost : 2.2064273357391357\n",
      "Epoch : 14, number of data 3072, cost : 2.2026407718658447\n",
      "Epoch : 14, number of data 3104, cost : 2.1950106620788574\n",
      "Epoch : 14, number of data 3136, cost : 2.217409133911133\n",
      "Epoch : 15, number of data 3168, cost : 2.207252025604248\n",
      "Epoch : 15, number of data 3200, cost : 2.200479745864868\n",
      "Epoch : 15, number of data 3232, cost : 2.2042832374572754\n",
      "Epoch : 15, number of data 3264, cost : 2.2052595615386963\n",
      "Epoch : 15, number of data 3296, cost : 2.204291343688965\n",
      "Epoch : 15, number of data 3328, cost : 2.193528890609741\n",
      "Epoch : 15, number of data 3360, cost : 2.2073283195495605\n",
      "Epoch : 16, number of data 3392, cost : 2.2019805908203125\n",
      "Epoch : 16, number of data 3424, cost : 2.2055211067199707\n",
      "Epoch : 16, number of data 3456, cost : 2.1979031562805176\n",
      "Epoch : 16, number of data 3488, cost : 2.2030344009399414\n",
      "Epoch : 16, number of data 3520, cost : 2.2115836143493652\n",
      "Epoch : 16, number of data 3552, cost : 2.200054168701172\n",
      "Epoch : 16, number of data 3584, cost : 2.1951465606689453\n",
      "Epoch : 17, number of data 3616, cost : 2.2049193382263184\n",
      "Epoch : 17, number of data 3648, cost : 2.2086007595062256\n",
      "Epoch : 17, number of data 3680, cost : 2.20097279548645\n",
      "Epoch : 17, number of data 3712, cost : 2.1924524307250977\n",
      "Epoch : 17, number of data 3744, cost : 2.201510429382324\n",
      "Epoch : 17, number of data 3776, cost : 2.2072696685791016\n",
      "Epoch : 17, number of data 3808, cost : 2.2165687084198\n",
      "Epoch : 18, number of data 3840, cost : 2.207221031188965\n",
      "Epoch : 18, number of data 3872, cost : 2.1999402046203613\n",
      "Epoch : 18, number of data 3904, cost : 2.2085461616516113\n",
      "Epoch : 18, number of data 3936, cost : 2.2019002437591553\n",
      "Epoch : 18, number of data 3968, cost : 2.197094440460205\n",
      "Epoch : 18, number of data 4000, cost : 2.200056791305542\n",
      "Epoch : 18, number of data 4032, cost : 2.2070064544677734\n",
      "Epoch : 19, number of data 4064, cost : 2.200443744659424\n",
      "Epoch : 19, number of data 4096, cost : 2.2012939453125\n",
      "Epoch : 19, number of data 4128, cost : 2.208710193634033\n",
      "Epoch : 19, number of data 4160, cost : 2.201108455657959\n",
      "Epoch : 19, number of data 4192, cost : 2.2061939239501953\n",
      "Epoch : 19, number of data 4224, cost : 2.205282688140869\n",
      "Epoch : 19, number of data 4256, cost : 2.2030420303344727\n",
      "Epoch : 20, number of data 4288, cost : 2.2007622718811035\n",
      "Epoch : 20, number of data 4320, cost : 2.205336570739746\n",
      "Epoch : 20, number of data 4352, cost : 2.2086682319641113\n",
      "Epoch : 20, number of data 4384, cost : 2.2014756202697754\n",
      "Epoch : 20, number of data 4416, cost : 2.2012667655944824\n",
      "Epoch : 20, number of data 4448, cost : 2.2030029296875\n",
      "Epoch : 20, number of data 4480, cost : 2.2032065391540527\n",
      "Epoch : 21, number of data 4512, cost : 2.2013773918151855\n",
      "Epoch : 21, number of data 4544, cost : 2.2040178775787354\n",
      "Epoch : 21, number of data 4576, cost : 2.2006311416625977\n",
      "Epoch : 21, number of data 4608, cost : 2.2063002586364746\n",
      "Epoch : 21, number of data 4640, cost : 2.204702377319336\n",
      "Epoch : 21, number of data 4672, cost : 2.2062177658081055\n",
      "Epoch : 21, number of data 4704, cost : 2.2031023502349854\n",
      "Epoch : 22, number of data 4736, cost : 2.195676326751709\n",
      "Epoch : 22, number of data 4768, cost : 2.202359199523926\n",
      "Epoch : 22, number of data 4800, cost : 2.2032032012939453\n",
      "Epoch : 22, number of data 4832, cost : 2.2062196731567383\n",
      "Epoch : 22, number of data 4864, cost : 2.2043681144714355\n",
      "Epoch : 22, number of data 4896, cost : 2.203249931335449\n",
      "Epoch : 22, number of data 4928, cost : 2.2118208408355713\n",
      "Epoch : 23, number of data 4960, cost : 2.2029664516448975\n",
      "Epoch : 23, number of data 4992, cost : 2.20475435256958\n",
      "Epoch : 23, number of data 5024, cost : 2.20345401763916\n",
      "Epoch : 23, number of data 5056, cost : 2.2003626823425293\n",
      "Epoch : 23, number of data 5088, cost : 2.1974010467529297\n",
      "Epoch : 23, number of data 5120, cost : 2.204664707183838\n",
      "Epoch : 23, number of data 5152, cost : 2.213435649871826\n",
      "Epoch : 24, number of data 5184, cost : 2.205014944076538\n",
      "Epoch : 24, number of data 5216, cost : 2.192136526107788\n",
      "Epoch : 24, number of data 5248, cost : 2.2042183876037598\n",
      "Epoch : 24, number of data 5280, cost : 2.2069735527038574\n",
      "Epoch : 24, number of data 5312, cost : 2.2038559913635254\n",
      "Epoch : 24, number of data 5344, cost : 2.2073163986206055\n",
      "Epoch : 24, number of data 5376, cost : 2.1881306171417236\n",
      "Epoch : 25, number of data 5408, cost : 2.198873519897461\n",
      "Epoch : 25, number of data 5440, cost : 2.1995325088500977\n",
      "Epoch : 25, number of data 5472, cost : 2.202552080154419\n",
      "Epoch : 25, number of data 5504, cost : 2.206394910812378\n",
      "Epoch : 25, number of data 5536, cost : 2.208843231201172\n",
      "Epoch : 25, number of data 5568, cost : 2.2013697624206543\n",
      "Epoch : 25, number of data 5600, cost : 2.20208477973938\n",
      "Epoch : 26, number of data 5632, cost : 2.2022204399108887\n",
      "Epoch : 26, number of data 5664, cost : 2.1992225646972656\n",
      "Epoch : 26, number of data 5696, cost : 2.2092766761779785\n",
      "Epoch : 26, number of data 5728, cost : 2.2021877765655518\n",
      "Epoch : 26, number of data 5760, cost : 2.208026885986328\n",
      "Epoch : 26, number of data 5792, cost : 2.2003333568573\n",
      "Epoch : 26, number of data 5824, cost : 2.196329355239868\n",
      "Epoch : 27, number of data 5856, cost : 2.2014856338500977\n",
      "Epoch : 27, number of data 5888, cost : 2.197000503540039\n",
      "Epoch : 27, number of data 5920, cost : 2.203601598739624\n",
      "Epoch : 27, number of data 5952, cost : 2.204268455505371\n",
      "Epoch : 27, number of data 5984, cost : 2.2045884132385254\n",
      "Epoch : 27, number of data 6016, cost : 2.206578254699707\n",
      "Epoch : 27, number of data 6048, cost : 2.2048895359039307\n",
      "Epoch : 28, number of data 6080, cost : 2.2007107734680176\n",
      "Epoch : 28, number of data 6112, cost : 2.204188346862793\n",
      "Epoch : 28, number of data 6144, cost : 2.2076687812805176\n",
      "Epoch : 28, number of data 6176, cost : 2.2039480209350586\n",
      "Epoch : 28, number of data 6208, cost : 2.2045364379882812\n",
      "Epoch : 28, number of data 6240, cost : 2.20172381401062\n",
      "Epoch : 28, number of data 6272, cost : 2.19589900970459\n",
      "Epoch : 29, number of data 6304, cost : 2.1964993476867676\n",
      "Epoch : 29, number of data 6336, cost : 2.2001161575317383\n",
      "Epoch : 29, number of data 6368, cost : 2.2052083015441895\n",
      "Epoch : 29, number of data 6400, cost : 2.2021942138671875\n",
      "Epoch : 29, number of data 6432, cost : 2.198119640350342\n",
      "Epoch : 29, number of data 6464, cost : 2.209312915802002\n",
      "Epoch : 29, number of data 6496, cost : 2.2078981399536133\n",
      "Epoch : 30, number of data 6528, cost : 2.1975579261779785\n",
      "Epoch : 30, number of data 6560, cost : 2.207977056503296\n",
      "Epoch : 30, number of data 6592, cost : 2.200688600540161\n",
      "Epoch : 30, number of data 6624, cost : 2.2042224407196045\n",
      "Epoch : 30, number of data 6656, cost : 2.197990655899048\n",
      "Epoch : 30, number of data 6688, cost : 2.2094874382019043\n",
      "Epoch : 30, number of data 6720, cost : 2.2084836959838867\n"
     ]
    }
   ],
   "source": [
    "data_trained = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainingloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = Lstm.forward(data[0])\n",
    "        true_results = data[1]\n",
    "\n",
    "        cost = loss_function(predictions, true_results)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        data_trained += 32\n",
    "\n",
    "        print(f\"Epoch : {e+1}, number of data {data_trained}, cost : {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.38888888888889%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, data in enumerate(testingloader):\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        if torch.argmax(prediction) == torch.argmax(data[1][n]):\n",
    "            correct += 1\n",
    "    \n",
    "print(f\"{correct/360*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Lstm, \"LSTM_model_30-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17ab35400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGexJREFUeJzt3QtwVPW9wPFfSMgGK1nekMhCIAqRp/KQi48qgjiZSNHe4WonTiM42tJQwLRW0l4FLwMLnSmDg0xAiuAMRMAKaJkBClRgqERIEAWxQAQhKJjaQjaEyway5875d8glyishv+S/Od/PzDHszm7yc5Psd88je2Icx3EEAAAlzbQ+MQAALkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQFfWhmT9/vqSkpEhCQoIMGTJEdu3aJTbZvn27jBo1SpKTkyUmJkbWrl0rtgkGgzJ48GBp2bKldOjQQR5//HE5ePCg2CQvL0/69esniYmJZhk6dKisX79ebDZr1izzPZ88ebLYZNq0aWauy5e0tDSxzVdffSVPP/20tG3bVlq0aCF9+/aVwsJCsYX7vPPdx9FdsrOzxRZVVVXy8ssvS7du3cxjmJqaKtOnT5eGfuexqA7NypUrJScnR6ZOnSp79uyR/v37y6OPPiqlpaVii4qKCjOXG0Rbbdu2zfxyFBQUyKZNm+TChQsycuRIM7stOnfubJ64i4qKzJPNww8/LKNHj5bPPvtMbLR7925ZuHChiaONevfuLSdPnqxeduzYITY5ffq03HfffdK8eXPzguLAgQPyhz/8QVq3bi02fY8vfwzd3x3XmDFjxBazZ882L9Jef/11+fzzz83l3//+9zJv3ryGHcSJYvfcc4+TnZ1dfbmqqspJTk52gsGgYyP34V6zZo1ju9LSUjPrtm3bHJu1bt3a+eMf/+jYpry83LnjjjucTZs2OQ8++KAzadIkxyZTp051+vfv79jspZdecu6//34nmrjf59TUVCcSiTi2yMjIcMaNG1fjuh//+MdOZmZmg84RtWs0lZWV5tXtiBEjqq9r1qyZubxz585GnS3alZWVmY9t2rQRG7mbA1asWGHWuNxNaLZx1w4zMjJq/Gza5vDhw2Zzbvfu3SUzM1OOHz8uNnn//fdl0KBBZu3A3Zx79913y6JFi8Tm56Nly5bJuHHjzOYzW9x7772yZcsWOXTokLn8ySefmLXX9PT0Bp0jTqLUt99+a55wOnbsWON69/Lf//73Rpsr2kUiEbNPwd1s0adPH7HJvn37TFjOnz8vt956q6xZs0Z69eolNnED6G7GdTer2Mrdl7l06VLp2bOn2eTz6quvygMPPCD79+83++lscOTIEbPJx900/tvf/tY8nhMnTpT4+HjJysoS27j7Xs+cOSPPPPOM2GTKlCkSCoXMPrjY2FjznDljxgzz4qIhRW1ooPdq3H3CsW2bvct9Yty7d69Z4/rTn/5knnDc/Uu2xKakpEQmTZpkttW7B6fY6vJXs+4+JDc8Xbt2lVWrVsmzzz4rtrzgcddoZs6caS67azTuz+WCBQusDM3ixYvN4+quJdpk1apVsnz5csnPzzf75dzfH/eFpDtnQz6OURuadu3amUJ/8803Na53L3fq1KnR5opmEyZMkHXr1pkj5dyd77ZxX83efvvt5t8DBw40r3Jfe+01s9PdBu6mXPdAlAEDBlRf576CdB9Pd2dsOBw2P7O2adWqlfTo0UOKi4vFFklJSd97AXHnnXfKu+++K7Y5duyYbN68WVavXi22efHFF81azVNPPWUuu0fuufO6R5o2ZGiidh+N+6TjPtm42x8vfxXkXrZxu73N3OMU3Mi4m6L++te/mkMho4H7/XafvG0xfPhws3nPfdV4aXFflbubKdx/2xgZ19mzZ+WLL74wT+62cDfdfvcQe3c/g7vmZZslS5aY/UjufjnbnDt3zuy7vpz7c+j+7jQoJ4qtWLHC8fl8ztKlS50DBw44zz//vNOqVSvn1KlTjk1HIH388cdmcR/uOXPmmH8fO3bMscX48eMdv9/vbN261Tl58mT1cu7cOccWU6ZMMUfBHT161Pn000/N5ZiYGOcvf/mLYzMbjzr71a9+Zb7X7mP5t7/9zRkxYoTTrl07c7ShLXbt2uXExcU5M2bMcA4fPuwsX77cueWWW5xly5Y5NnGPdO3SpYs5Ss5GWVlZzm233easW7fOfL9Xr15tvte/+c1vGnSOqA6Na968eeYbHR8fbw53LigocGzywQcfmMB8d3F/AGxxpfncZcmSJY4t3EM0u3btar7P7du3d4YPH259ZGwNzZNPPukkJSWZx9J9EnIvFxcXO7b585//7PTp08e8mExLS3PeeOMNxzYbN240vysHDx50bBQKhczPn/scmZCQ4HTv3t353e9+54TD4QadI8b9T8OuQwEAvCRq99EAAKIDoQEAqCI0AABVhAYAoIrQAABUERoAgKqoD437l+HuiZxs+gvxaJ2TGb01JzN6a85wI84Y9X9H474zqd/vN2+06J550VbRMCczemtOZvTWnKFGnDHq12gAAHYjNACApnWaAPddQ7/++mtzgqX6OBOduzp4+UdbRcOczOitOZnRW3OGFGZ097yUl5eb89t8912iG3UfzYkTJyQQCDTklwQAKJ/071rnsGrwNZpLp4q964n/ltjm9p6F8Hxrtip6ScedZY09QpPRrPS02O7k6BSJBuFWYrVI+Lwcmfs/1z0FeIOH5tLmMjcyNocmNp7QeElc7PnGHqHJaNYsXmwXG2/vc8/lYn0SFa63G4RnUwCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQBAFaEBAKgiNAAA+0Izf/58SUlJkYSEBBkyZIjs2rWr/icDAHgzNCtXrpScnByZOnWq7NmzR/r37y+PPvqolJaW6kwIAPBWaObMmSPPPfecjB07Vnr16iULFiyQW265Rd58802dCQEA3glNZWWlFBUVyYgRI/7/EzRrZi7v3LnzivcJh8MSCoVqLAAA76hVaL799lupqqqSjh071rjevXzq1Kkr3icYDIrf769eAoHAzU0MAIgq6ked5ebmSllZWfVSUlKi/SUBABaJq82N27VrJ7GxsfLNN9/UuN693KlTpyvex+fzmQUA4E21WqOJj4+XgQMHypYtW6qvi0Qi5vLQoUM15gMAeGmNxuUe2pyVlSWDBg2Se+65R+bOnSsVFRXmKDQAAG46NE8++aT84x//kFdeecUcAHDXXXfJhg0bvneAAAAAdQqNa8KECWYBAOB6eK8zAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEA2PfuzfWh5ardEhfTXGyVKNEhLunKZzZF7fxrWIpEg1YHQmK7SMc2YrsOr3/Y2CM0CRedC1J8A7djjQYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAALtCs337dhk1apQkJydLTEyMrF27VmcyAIA3Q1NRUSH9+/eX+fPn60wEAPD2qZzT09PNAgCASmhqKxwOm+WSUMj+c54DAKLoYIBgMCh+v796CQQC2l8SAOCl0OTm5kpZWVn1UlJSov0lAQBe2nTm8/nMAgDwJv6OBgBg1xrN2bNnpbi4uPry0aNHZe/evdKmTRvp0qVLfc8HAPBaaAoLC2XYsGHVl3NycszHrKwsWbp0af1OBwDwXmgeeughcRxHZxoAQJPDPhoAgCpCAwBQRWgAAKoIDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAgOg+lTN0XTx5qrFHaBIS86PjcYw09gBAHbBGAwBQRWgAAKoIDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAPaEJBoMyePBgadmypXTo0EEef/xxOXjwoN50AABvhWbbtm2SnZ0tBQUFsmnTJrlw4YKMHDlSKioq9CYEAHjnVM4bNmyocXnp0qVmzaaoqEh++MMfXvE+4XDYLJeEQqG6zgoA8No+mrKyMvOxTZs219zc5vf7q5dAIHAzXxIAEGViHMdx6nLHSCQiP/rRj+TMmTOyY8eOq97uSms0bmwektESF9O8blMDABrdReeCbJX3zEpHYmJi/Ww6u5y7r2b//v3XjIzL5/OZBQDgTXUKzYQJE2TdunWyfft26dy5c/1PBQDwZmjcrWy//OUvZc2aNbJ161bp1q2b3mQAAO+Fxt1clp+fL++99575W5pTp06Z692d/C1atNCaEQDglaPO8vLyzE6fhx56SJKSkqqXlStX6k0IAPDWpjMAAGqD9zoDAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAqjqfyvlmlf/XYIltniC2avPBl409QpPxr2EpYrsW316UaHBqSLzYrtNHlWK70z3sfxxdye8eEatFKkX+fVqya2KNBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQBAFaEBAKgiNAAAe0KTl5cn/fr1k8TERLMMHTpU1q9frzcdAMBboencubPMmjVLioqKpLCwUB5++GEZPXq0fPbZZ3oTAgC8cyrnUaNG1bg8Y8YMs5ZTUFAgvXv3ru/ZAABeC83lqqqq5J133pGKigqzCe1qwuGwWS4JhUJ1/ZIAAC8cDLBv3z659dZbxefzyc9//nNZs2aN9OrV66q3DwaD4vf7q5dAIHCzMwMAmnJoevbsKXv37pWPPvpIxo8fL1lZWXLgwIGr3j43N1fKysqql5KSkpudGQDQlDedxcfHy+23327+PXDgQNm9e7e89tprsnDhwive3l3zcRcAgDfd9N/RRCKRGvtgAACo8xqNuxksPT1dunTpIuXl5ZKfny9bt26VjRs31ubTAAA8pFahKS0tlZ/+9Kdy8uRJs2Pf/eNNNzKPPPKI3oQAAO+EZvHixXqTAACaJN7rDACgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAHadYbO+lD58QZq1iBVblQ5OaewR0IA67G60X4VaOZ9q/0kGv0yVKGD/4/hv3cVmVZXnRa58cuUaWKMBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAMDe0MyaNUtiYmJk8uTJ9TcRAKBJqXNodu/eLQsXLpR+/frV70QAgCalTqE5e/asZGZmyqJFi6R169b1PxUAwNuhyc7OloyMDBkxYsR1bxsOhyUUCtVYAADeEVfbO6xYsUL27NljNp3diGAwKK+++mpdZgMAeG2NpqSkRCZNmiTLly+XhISEG7pPbm6ulJWVVS/u5wAAeEet1miKioqktLRUBgwYUH1dVVWVbN++XV5//XWzmSw2NrbGfXw+n1kAAN5Uq9AMHz5c9u3bV+O6sWPHSlpamrz00kvfiwwAALUKTcuWLaVPnz41rvvBD34gbdu2/d71AAC4eGcAAIBdR51919atW+tnEgBAk8QaDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCA3acJqKue005KXLN4sdXFk6cae4Qmo9ldvcR2X09zJBrc8fjnYru4pE6NPUKTEenYRmx2sSosn93A7VijAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQDAntBMmzZNYmJiaixpaWl60wEAvHeGzd69e8vmzZv//xPENdpJOgEAUaDWlXDD0qnTjZ+qNRwOm+WSUChU2y8JAPDSPprDhw9LcnKydO/eXTIzM+X48ePXvH0wGBS/31+9BAKBm5kXANCUQzNkyBBZunSpbNiwQfLy8uTo0aPywAMPSHl5+VXvk5ubK2VlZdVLSUlJfcwNAGiKm87S09Or/92vXz8Tnq5du8qqVavk2WefveJ9fD6fWQAA3nRThze3atVKevToIcXFxfU3EQCgSbmp0Jw9e1a++OILSUpKqr+JAADeDc2vf/1r2bZtm3z55Zfy4YcfyhNPPCGxsbHyk5/8RG9CAIB39tGcOHHCROWf//yntG/fXu6//34pKCgw/wYA4KZDs2LFitrcHAAA3usMAKCL0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAA9rx7c33q+U6p+G5tLrba/Oa9Eg0S/hUR25UOFuv1mBaSaHDsZft/Ls+nhsV2CV9Ex+nlw23s/v2OnD8v8un1b8caDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAdoXmq6++kqefflratm0rLVq0kL59+0phYaHOdAAAb51h8/Tp03LffffJsGHDZP369dK+fXs5fPiwtG7dWm9CAIB3QjN79mwJBAKyZMmS6uu6deumMRcAwIubzt5//30ZNGiQjBkzRjp06CB33323LFq06Jr3CYfDEgqFaiwAAO+oVWiOHDkieXl5cscdd8jGjRtl/PjxMnHiRHnrrbeuep9gMCh+v796cdeIAADeUavQRCIRGTBggMycOdOszTz//PPy3HPPyYIFC656n9zcXCkrK6teSkpK6mNuAEBTDE1SUpL06tWrxnV33nmnHD9+/Kr38fl8kpiYWGMBAHhHrULjHnF28ODBGtcdOnRIunbtWt9zAQC8GJoXXnhBCgoKzKaz4uJiyc/PlzfeeEOys7P1JgQAeCc0gwcPljVr1sjbb78tffr0kenTp8vcuXMlMzNTb0IAgHf+jsb12GOPmQUAgBvBe50BAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQDArndvri9bl90jsfEJYquyQWGJBi/8x3tiu33nAmK7z+/uJNGgu5wW2x3Z0k1s1334UYkGB75MFps5/3vhhm7HGg0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAPaEJiUlRWJiYr63ZGdn600IAPDOGTZ3794tVVVV1Zf3798vjzzyiIwZM0ZjNgCA10LTvn37GpdnzZolqamp8uCDD9b3XAAAL4bmcpWVlbJs2TLJyckxm8+uJhwOm+WSUChU1y8JAPDSwQBr166VM2fOyDPPPHPN2wWDQfH7/dVLIBCo65cEAHgpNIsXL5b09HRJTk6+5u1yc3OlrKyseikpKanrlwQAeGXT2bFjx2Tz5s2yevXq697W5/OZBQDgTXVao1myZIl06NBBMjIy6n8iAIC3QxOJRExosrKyJC6uzscSAAA8otahcTeZHT9+XMaNG6czEQCgSan1KsnIkSPFcRydaQAATQ7vdQYAUEVoAACqCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoKrRzlxW3i0izRIiYqsjIxdLNHjsULrY7tzM28R2p4bEN/YITUbGEzvFdpvfHCrR4D/H2f1Yhs9ekPk3cDvWaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwBQRWgAAKoIDQBAFaEBAKgiNAAAVYQGAKCK0AAAVBEaAIAqQgMAsCc0VVVV8vLLL0u3bt2kRYsWkpqaKtOnTxfHcfQmBAB45wybs2fPlry8PHnrrbekd+/eUlhYKGPHjhW/3y8TJ07UmxIA4I3QfPjhhzJ69GjJyMgwl1NSUuTtt9+WXbt2XfU+4XDYLJeEQqGbmRcA0JQ3nd17772yZcsWOXTokLn8ySefyI4dOyQ9/ernrQ8Gg2aN59ISCARufmoAQNNco5kyZYpZI0lLS5PY2Fizz2bGjBmSmZl51fvk5uZKTk5O9WX3/sQGALyjVqFZtWqVLF++XPLz880+mr1798rkyZMlOTlZsrKyrngfn89nFgCAN9UqNC+++KJZq3nqqafM5b59+8qxY8fM5rGrhQYA4G212kdz7tw5adas5l3cTWiRSKS+5wIAeHGNZtSoUWafTJcuXcyms48//ljmzJkj48aN05sQAOCd0MybN8/8weYvfvELKS0tNftmfvazn8krr7yiNyEAwDuhadmypcydO9csAADcCN7rDACgitAAAFQRGgCAKkIDAFBFaAAAqggNAEAVoQEAqCI0AABVhAYAoIrQAABUERoAgCpCAwCw500164PjOOZj5Px5sVmoPDrOsXOholJsd/Gi3d9rV1U4Or7f0SB89oLYrqrS/p/JaHgsKysu1Hhev5oY53q3qGcnTpyQQCDQkF8SAKCopKREOnfubE9o3LNxfv311+aUAzExMTf9+UKhkAmX+z+amJgotoqGOZnRW3Myo7fmDCnM6OajvLzcnJvsu2dfbtRNZ+4w1ypfXbkPnK3f4Gibkxm9NSczemvOxHqe0e/3X/c2HAwAAFBFaAAAqqI+ND6fT6ZOnWo+2iwa5mRGb83JjN6a09eIMzb4wQAAAG+J+jUaAIDdCA0AQBWhAQCoIjQAAFWEBgCgitAAAFQRGgCAKkIDABBN/wcBcjdpSksAjgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.zeros((9, 9))\n",
    "\n",
    "for data in testingloader:\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        results[torch.argmax(prediction)][torch.argmax(data[1][n])] += 1\n",
    "\n",
    "plt.matshow(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pole_ia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
