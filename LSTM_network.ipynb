{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdirs = [\"Healthy\", \"Motor_1_Steady_state_error\", \"Motor_1_Stuck\", \"Motor_2_Steady_state_error\", \"Motor_2_Stuck\", \"Motor_3_Steady_state_error\", \"Motor_3_Stuck\", \"Motor_4_Steady_state_error\", \"Motor_4_Stuck\"]\n",
    "path = \"training_csv/\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_ratio:float, training:bool, path, directories_list, backend):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.backend = backend\n",
    "        self.training_ratio = training_ratio\n",
    "        self.directories_list = directories_list\n",
    "        self.simulations = []\n",
    "        self.classes = []\n",
    "\n",
    "        for i, folder in enumerate(self.directories_list):\n",
    "            folderpath = os.path.join(path, folder)\n",
    "            files = os.listdir(folderpath)\n",
    "            number_files = len(files)\n",
    "            for n, file in enumerate(files):\n",
    "                if n < self.training_ratio * number_files and training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32)\n",
    "                    tensor[:,3:] -= tensor[:,:3]\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True)\n",
    "                    self.simulations.append(standardized_tensor)\n",
    "                    self.classes.append(torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16))\n",
    "                elif n >= self.training_ratio * number_files and not training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32)\n",
    "                    tensor[:,3:] -= tensor[:,:3]\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True)\n",
    "                    self.simulations.append(standardized_tensor)\n",
    "                    self.classes.append(torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16))\n",
    "        \n",
    "        self.simulations = torch.stack(self.simulations)\n",
    "        self.classes = torch.stack(self.classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.simulations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.simulations[index], self.classes[index])\n",
    "    \n",
    "training_set = dataset(training_ratio=0.9, training=True, path=path, directories_list=listdirs, backend=device)\n",
    "trainingloader = torch.utils.data.DataLoader(training_set, shuffle=True, batch_size=32)\n",
    "\n",
    "testing_set = dataset(training_ratio=0.9, training=False, path=path, directories_list=listdirs, backend=device)\n",
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3240, 9]) torch.Size([3240, 999, 6]) torch.Size([3240, 9]) torch.Size([3240, 999, 6])\n"
     ]
    }
   ],
   "source": [
    "print(training_set.classes.shape, training_set.simulations.shape, training_set.classes.shape, training_set.simulations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, hidden_size, backend):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.backend = backend\n",
    "\n",
    "        self.LSTM = nn.LSTM(input_size=6, hidden_size=self.hidden_size, dropout=0.1, device=self.backend, batch_first=True, num_layers=2)\n",
    "        self.Linear = nn.Linear(in_features=self.hidden_size, out_features=9, device=self.backend)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM(x)[0][:,-1]\n",
    "        x = self.Linear(x)\n",
    "        return x\n",
    "    \n",
    "Lstm = LSTM_model(100, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Lstm.parameters(), lr=1E-3)\n",
    "epochs = 250 - 14\n",
    "patience = 10\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode=\"min\", factor=0.5, patience=patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, training cost : 1.3453145027160645\n",
      "Epoch : 1, testing cost : 1.8513163328170776, accuracy : 33.88888888888889%\n",
      "Epoch : 2, training cost : 0.7805802226066589\n",
      "Epoch : 2, testing cost : 1.9214913845062256, accuracy : 30.277777777777775%\n",
      "Epoch : 3, training cost : 1.9239333868026733\n",
      "Epoch : 3, testing cost : 1.96316659450531, accuracy : 31.944444444444443%\n",
      "Epoch : 4, training cost : 1.4180281162261963\n",
      "Epoch : 4, testing cost : 2.018843173980713, accuracy : 25.27777777777778%\n",
      "Epoch : 5, training cost : 0.9065353870391846\n",
      "Epoch : 5, testing cost : 1.9244189262390137, accuracy : 28.888888888888886%\n",
      "Epoch : 6, training cost : 1.398040771484375\n",
      "Epoch : 6, testing cost : 2.2277565002441406, accuracy : 19.444444444444446%\n",
      "Epoch : 7, training cost : 1.0046190023422241\n",
      "Epoch : 7, testing cost : 2.305088520050049, accuracy : 26.944444444444443%\n",
      "Epoch : 8, training cost : 1.250449776649475\n",
      "Epoch : 8, testing cost : 1.9276750087738037, accuracy : 27.22222222222222%\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainingloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = Lstm.forward(data[0].to(device))\n",
    "        true_results = data[1].to(device)\n",
    "\n",
    "        cost = loss_function(predictions, true_results)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch : {e+1}, training cost : {cost}\")\n",
    "\n",
    "    Lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        accurate = 0\n",
    "        test_predictions = Lstm.forward(testing_set.simulations.to(device))\n",
    "        testing_set.classes = testing_set.classes.to(device)\n",
    "        for n, prediction in enumerate(test_predictions):\n",
    "            if torch.argmax(prediction) == torch.argmax(testing_set.classes[n]):\n",
    "                accurate += 1\n",
    "        cost = loss_function(test_predictions, testing_set.classes)\n",
    "        print(f\"Epoch : {e+1}, testing cost : {cost}, accuracy : {accurate/len(testing_set)*100}%\")\n",
    "        scheduler.step(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 11.11111111111111 ‰ F1 score : [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "Lstm.zero_grad()\n",
    "VP = FP = FN = np.zeros(9)\n",
    "correct = 0\n",
    "for i, data in enumerate(testingloader):\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        response = torch.argmax(prediction)\n",
    "        true_result = torch.argmax(data[1][n])\n",
    "        if response == true_result:\n",
    "            VP[true_result] += 1\n",
    "            correct += 1\n",
    "        else:\n",
    "            FP[response] += 1\n",
    "            FN[true_result] += 1\n",
    "\n",
    "precision = VP/(VP+FP)\n",
    "recall = VP/(VP+FN)\n",
    "print(f\"Accuracy : {correct/360*100} ‰\", f\"F1 score : {2*precision*recall/(precision+recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Lstm, \"LSTM_model_30-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15c20aff0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.zeros((9, 9))\n",
    "\n",
    "for data in testingloader:\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        results[torch.argmax(prediction)][torch.argmax(data[1][n])] += 1\n",
    "\n",
    "plt.matshow(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
