{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdirs = [\"Healthy\", \"Motor_1_Steady_state_error\", \"Motor_1_Stuck\", \"Motor_2_Steady_state_error\", \"Motor_2_Stuck\", \"Motor_3_Steady_state_error\", \"Motor_3_Stuck\", \"Motor_4_Steady_state_error\", \"Motor_4_Stuck\"]\n",
    "path = \"training_csv/\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_ratio:float, training:bool, path, directories_list, backend):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.backend = backend\n",
    "        self.training_ratio = training_ratio\n",
    "        self.directories_list = directories_list\n",
    "        self.data = []\n",
    "\n",
    "        for i, folder in enumerate(self.directories_list):\n",
    "            folderpath = os.path.join(path, folder)\n",
    "            files = os.listdir(folderpath)\n",
    "            number_files = len(files)\n",
    "            for n, file in enumerate(files):\n",
    "                if n < self.training_ratio * number_files and training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32).to(self.backend)\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "                elif n >= self.training_ratio * number_files and not training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32).to(self.backend)\n",
    "                    standardized_tensor = (tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "training_set = dataset(training_ratio=0.9, training=True, path=path, directories_list=listdirs, backend=device)\n",
    "trainingloader = torch.utils.data.DataLoader(training_set, shuffle=True, batch_size=512)\n",
    "\n",
    "testing_set = dataset(training_ratio=0.9, training=False, path=path, directories_list=listdirs, backend=device)\n",
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{torch.Size([999, 6]): 3240} {torch.Size([999, 6]): 360}\n"
     ]
    }
   ],
   "source": [
    "shapes1 = {}\n",
    "for data in training_set.data:\n",
    "    if data[0].shape not in shapes1.keys():\n",
    "        shapes1[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes1[data[0].shape] += 1\n",
    "\n",
    "shapes2 = {}\n",
    "for data in testing_set.data:\n",
    "    if data[0].shape not in shapes2.keys():\n",
    "        shapes2[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes2[data[0].shape] += 1\n",
    "\n",
    "print(shapes1, shapes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, hidden_size, backend):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.backend = backend\n",
    "\n",
    "        self.LSTM = nn.LSTM(input_size=6, hidden_size=self.hidden_size, dropout=0.1, device=self.backend, batch_first=True, num_layers=2)\n",
    "        self.Linear = nn.Linear(in_features=self.hidden_size, out_features=9, device=self.backend)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM(x)[0]\n",
    "        x = self.Linear(x)\n",
    "        return x[:,-1]\n",
    "    \n",
    "Lstm = LSTM_model(125, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Lstm.parameters(), lr=1E-3)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.23 GB, other allocations: 13.30 GB, max allowed: 18.13 GB). Tried to allocate 2.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m true_results = data[\u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m cost = loss_function(predictions, true_results)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m optimizer.step()\n\u001b[32m     15\u001b[39m data_trained += \u001b[32m32\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 5.23 GB, other allocations: 13.30 GB, max allowed: 18.13 GB). Tried to allocate 2.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "data_trained = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainingloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = Lstm.forward(data[0])\n",
    "        true_results = data[1]\n",
    "\n",
    "        cost = loss_function(predictions, true_results)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        data_trained += 32\n",
    "\n",
    "        print(f\"Epoch : {e+1}, number of data {data_trained}, cost : {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.27777777777778%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, data in enumerate(testingloader):\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        if torch.argmax(prediction) == torch.argmax(data[1][n]):\n",
    "            correct += 1\n",
    "    \n",
    "print(f\"{correct/360*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Lstm, \"LSTM_model_30-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x351278c20>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.zeros((9, 9))\n",
    "\n",
    "for data in testingloader:\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        results[torch.argmax(prediction)][torch.argmax(data[1][n])] += 1\n",
    "\n",
    "plt.matshow(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
