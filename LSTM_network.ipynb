{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdirs = [\"Healthy\", \"Motor_1_Steady_state_error\", \"Motor_1_Stuck\", \"Motor_2_Steady_state_error\", \"Motor_2_Stuck\", \"Motor_3_Steady_state_error\", \"Motor_3_Stuck\", \"Motor_4_Steady_state_error\", \"Motor_4_Stuck\"]\n",
    "path = \"training_csv/\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_ratio:float, training:bool, path, directories_list, backend):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.backend = backend\n",
    "        self.training_ratio = training_ratio\n",
    "        self.directories_list = directories_list\n",
    "        self.data = []\n",
    "\n",
    "        for i, folder in enumerate(self.directories_list):\n",
    "            folderpath = os.path.join(path, folder)\n",
    "            files = os.listdir(folderpath)\n",
    "            number_files = len(files)\n",
    "            for n, file in enumerate(files):\n",
    "                if n < self.training_ratio * number_files and training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32)\n",
    "                    tensor[:,3:] -= tensor[:,:3]\n",
    "                    standardized_tensor = ((tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True)).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "                elif n >= self.training_ratio * number_files and not training:\n",
    "                    open_file = pd.read_csv(os.path.join(folderpath, file))\n",
    "                    tensor = torch.tensor(open_file.values, dtype=torch.float32)\n",
    "                    tensor[:,3:] -= tensor[:,3:]\n",
    "                    standardized_tensor = ((tensor - tensor.mean(dim=0, keepdim=True))/tensor.std(dim=0, keepdim=True)).to(self.backend)\n",
    "                    self.data.append((standardized_tensor, torch.nn.functional.one_hot(torch.tensor([i]), num_classes=9)[0].type(torch.float16).to(self.backend)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "training_set = dataset(training_ratio=0.9, training=True, path=path, directories_list=listdirs, backend=device)\n",
    "trainingloader = torch.utils.data.DataLoader(training_set, shuffle=True, batch_size=512)\n",
    "\n",
    "testing_set = dataset(training_ratio=0.9, training=False, path=path, directories_list=listdirs, backend=device)\n",
    "testingloader = torch.utils.data.DataLoader(testing_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3628,  0.1091,  1.8925,  0.1333,  0.3149,  0.0138],\n",
      "        [-0.3624,  0.0979,  1.8909,  0.1205,  0.6504,  0.0405],\n",
      "        [-0.3617,  0.0868,  1.8882,  0.1001,  0.9206,  0.0827],\n",
      "        ...,\n",
      "        [ 2.2503, -0.2919, -1.0140,  0.1376, -0.0551,  0.0048],\n",
      "        [ 2.2503, -0.2919, -1.0140,  0.1376, -0.0551,  0.0048],\n",
      "        [ 2.2503, -0.2919, -1.0140,  0.1376, -0.0551,  0.0048]],\n",
      "       device='mps:0') torch.Size([999, 6])\n"
     ]
    }
   ],
   "source": [
    "print(training_set.data[5][0], testing_set.data[5][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{torch.Size([999, 6]): 3240} {torch.Size([999, 6]): 360}\n"
     ]
    }
   ],
   "source": [
    "shapes1 = {}\n",
    "for data in training_set.data:\n",
    "    if data[0].shape not in shapes1.keys():\n",
    "        shapes1[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes1[data[0].shape] += 1\n",
    "\n",
    "shapes2 = {}\n",
    "for data in testing_set.data:\n",
    "    if data[0].shape not in shapes2.keys():\n",
    "        shapes2[data[0].shape] = 1\n",
    "    else:\n",
    "        shapes2[data[0].shape] += 1\n",
    "\n",
    "print(shapes1, shapes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, hidden_size, backend):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.backend = backend\n",
    "\n",
    "        self.LSTM = nn.LSTM(input_size=6, hidden_size=self.hidden_size, dropout=0.1, device=self.backend, batch_first=True, num_layers=2)\n",
    "        self.Linear = nn.Linear(in_features=self.hidden_size, out_features=9, device=self.backend)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LSTM(x)[0]\n",
    "        x = self.Linear(x)\n",
    "        return x[:,-1]\n",
    "    \n",
    "Lstm = LSTM_model(125, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(Lstm.parameters(), lr=1E-3)\n",
    "epochs = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.23 GB, other allocations: 13.30 GB, max allowed: 18.13 GB). Tried to allocate 2.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m true_results = data[\u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m cost = loss_function(predictions, true_results)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m optimizer.step()\n\u001b[32m     15\u001b[39m data_trained += \u001b[32m32\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personnel/Documents/Cours/Cycle ingé/1A/Projet IA/project/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 5.23 GB, other allocations: 13.30 GB, max allowed: 18.13 GB). Tried to allocate 2.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "data_trained = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainingloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = Lstm.forward(data[0])\n",
    "        true_results = data[1]\n",
    "\n",
    "        cost = loss_function(predictions, true_results)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        data_trained += 32\n",
    "\n",
    "        print(f\"Epoch : {e+1}, number of data {data_trained}, cost : {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 11.11111111111111 ‰ F1 score : [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "Lstm.zero_grad()\n",
    "VP = FP = FN = np.zeros(9)\n",
    "correct = 0\n",
    "for i, data in enumerate(testingloader):\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        response = torch.argmax(prediction)\n",
    "        true_result = torch.argmax(data[1][n])\n",
    "        if response == true_result:\n",
    "            VP[true_result] += 1\n",
    "            correct += 1\n",
    "        else:\n",
    "            FP[response] += 1\n",
    "            FN[true_result] += 1\n",
    "\n",
    "precision = VP/(VP+FP)\n",
    "recall = VP/(VP+FN)\n",
    "print(f\"Accuracy : {correct/360*100} ‰\", f\"F1 score : {2*precision*recall/(precision+recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Lstm, \"LSTM_model_30-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15c20aff0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.zeros((9, 9))\n",
    "\n",
    "for data in testingloader:\n",
    "    predictions = Lstm.forward(data[0])\n",
    "\n",
    "    for n, prediction in enumerate(predictions):\n",
    "        results[torch.argmax(prediction)][torch.argmax(data[1][n])] += 1\n",
    "\n",
    "plt.matshow(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
